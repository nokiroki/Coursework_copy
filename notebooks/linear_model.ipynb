{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейные модели"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('..', 'data', 'creditcard.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(clf, data_train, target_train, data_test, target_test):\n",
    "    train_pred = clf.predict(data_train)\n",
    "    test_pred = clf.predict(data_test)\n",
    "\n",
    "    train_pred_proba = clf.predict_proba(data_train)[:, 1]\n",
    "    test_pred_proba = clf.predict_proba(data_test)[:, 1]\n",
    "    \n",
    "\n",
    "    print(f'f1 score train - {f1_score(target_train, train_pred)}')\n",
    "    print(f'f1 score test - {f1_score(target_test, test_pred)}')\n",
    "\n",
    "    print(f'rocauc score train - {roc_auc_score(target_train, train_pred_proba)}')\n",
    "    print(f'rocauc score test - {roc_auc_score(target_test, test_pred_proba)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount_log'] = np.log(df['Amount'] + 1e-9)\n",
    "df.drop(columns=['Amount', 'Time'], axis=1, inplace=True)\n",
    "data, target = df.drop(columns=['Class'], axis=1), df['Class']\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=.2, stratify=target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бейзлайн"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем предсказывать случайно. Во время EDA мы обнаружили, что только 0.1 процент данных - аномальные. заполним массив нулями и случайно инициализируем $5\\%$ аномальных данных - это и будет наш бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = np.zeros_like(target_train)\n",
    "test_pred = np.zeros_like(target_test)\n",
    "\n",
    "train_pred[:int(train_pred.shape[0] * .05)] = 1\n",
    "test_pred[:int(test_pred.shape[0] * .05)] = 1\n",
    "\n",
    "np.random.shuffle(train_pred)\n",
    "np.random.shuffle(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score train - 0.0027150856948922448\n",
      "f1 score test - 0.006109979633401223\n"
     ]
    }
   ],
   "source": [
    "print(f'f1 score train - {f1_score(target_train, train_pred)}')\n",
    "print(f'f1 score test - {f1_score(target_test, test_pred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score train - 0.7194029850746269\n",
      "f1 score test - 0.7349397590361446\n",
      "rocauc score train - 0.9757468708550089\n",
      "rocauc score test - 0.9823495802372721\n"
     ]
    }
   ],
   "source": [
    "lg_base = LogisticRegression()\n",
    "lg_base.fit(data_train, target_train)\n",
    "\n",
    "print_metrics(lg_base, data_train, target_train, data_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "\n",
    "params = {\n",
    "    'C': np.linspace(0.1, 1, 15),\n",
    "    'warm_start': (True, False)\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(5)\n",
    "\n",
    "skf.get_n_splits(data_train, target_train)\n",
    "\n",
    "gs = GridSearchCV(lg, params, scoring='f1', cv=skf, n_jobs=-1, verbose=5)\n",
    "\n",
    "gs.fit(data_train, target_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 0.7428571428571429, 'warm_start': True}, 0.7190732025476552)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score train - 0.7194029850746269\n",
      "f1 score test - 0.7349397590361446\n",
      "rocauc score train - 0.9758331280679475\n",
      "rocauc score test - 0.9823998254338313\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression(**gs.best_params_)\n",
    "lg.fit(data_train, target_train)\n",
    "\n",
    "print_metrics(lg, data_train, target_train, data_test, target_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score train - 0.9434484445491277\n",
      "f1 score test - 0.10650887573964497\n",
      "rocauc score train - 0.98874841980504\n",
      "rocauc score test - 0.9857170850895226\n"
     ]
    }
   ],
   "source": [
    "data_train_resampled, target_train_resampled = SMOTE().fit_resample(data_train, target_train)\n",
    "\n",
    "lg = LogisticRegression(**gs.best_params_)\n",
    "lg.fit(data_train_resampled, target_train_resampled)\n",
    "\n",
    "print_metrics(lg, data_train_resampled, target_train_resampled, data_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score train - 0.884847638189143\n",
      "f1 score test - 0.035583059369561014\n",
      "rocauc score train - 0.9617903690970029\n",
      "rocauc score test - 0.9771648142937535\n"
     ]
    }
   ],
   "source": [
    "data_train_resampled, target_train_resampled = ADASYN().fit_resample(data_train, target_train)\n",
    "\n",
    "lg = LogisticRegression(**gs.best_params_)\n",
    "lg.fit(data_train_resampled, target_train_resampled)\n",
    "\n",
    "print_metrics(lg, data_train_resampled, target_train_resampled, data_test, target_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\n.Belousov\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "isol_for = IsolationForest(contamination=.01)\n",
    "\n",
    "isol_for.fit(data_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = isol_for.predict(data_train)\n",
    "test_pred = isol_for.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = np.clip(train_pred, 0, 1)\n",
    "train_pred = np.where((train_pred == 0) | (train_pred == 1), train_pred^1, train_pred)\n",
    "\n",
    "test_pred = np.clip(test_pred, 0, 1)\n",
    "test_pred = np.where((test_pred == 0) | (test_pred == 1), test_pred^1, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score train - 0.18930041152263372\n",
      "f1 score test - 0.19402985074626866\n"
     ]
    }
   ],
   "source": [
    "print(f'f1 score train - {f1_score(target_train, train_pred)}')\n",
    "print(f'f1 score test - {f1_score(target_test, test_pred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = OneClassSVM(kernel='linear')\n",
    "\n",
    "svm.fit(data_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = svm.predict(data_train)\n",
    "test_pred = svm.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = np.clip(train_pred, 0, 1)\n",
    "train_pred = np.where((train_pred == 0) | (train_pred == 1), train_pred^1, train_pred)\n",
    "\n",
    "test_pred = np.clip(test_pred, 0, 1)\n",
    "test_pred = np.where((test_pred == 0) | (test_pred == 1), test_pred^1, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score train - 0.18930041152263372\n",
      "f1 score test - 0.19402985074626866\n"
     ]
    }
   ],
   "source": [
    "print(f'f1 score train - {f1_score(target_train, train_pred)}')\n",
    "print(f'f1 score test - {f1_score(target_test, test_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
